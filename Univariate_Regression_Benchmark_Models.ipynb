{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Benchmark Models\n",
    "1. LOWESS\n",
    "2. Smothing Splines\n",
    "3. Deep feed-forward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOWESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LOESS(data_x,data_x_test,data_y):\n",
    "    # Initializations #\n",
    "    #-----------------#\n",
    "    from scipy.interpolate import interp1d\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    # Coerce Data #\n",
    "    #=============#\n",
    "    # Training Data\n",
    "    data_y_vec = np.array(data_y)\n",
    "    data_x_vec = np.array(data_x).reshape(-1,)\n",
    "    # Testing Data\n",
    "    data_x_test_vec = np.array(data_x_test).reshape(-1,)\n",
    "    \n",
    "    # Train LOESS #\n",
    "    #=============#\n",
    "    LOESS = sm.nonparametric.lowess\n",
    "    f_hat_LOESS = LOESS(data_y_vec,data_x_vec.reshape(-1,))\n",
    "    LOESS_x = list(zip(*f_hat_LOESS))[0]\n",
    "    f_hat_LOESS = list(zip(*f_hat_LOESS))[1]\n",
    "    \n",
    "    # Get LOESS Prediction(s) #\n",
    "    #-------------------------#\n",
    "    # Train\n",
    "    f = interp1d(LOESS_x, f_hat_LOESS, bounds_error=False)\n",
    "    LOESS_prediction_train = f(data_x_vec)\n",
    "    LOESS_prediction_train = np.nan_to_num(LOESS_prediction_train)\n",
    "    # Test\n",
    "    LOESS_prediction_test = f(data_x_test_vec)\n",
    "    LOESS_prediction_test = np.nan_to_num(LOESS_prediction_test)\n",
    "    \n",
    "    # Return LOESS Outputs\n",
    "    return LOESS_prediction_train, LOESS_prediction_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions from training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOESS_prediction_train, LOESS_prediction_test = get_LOESS(data_x,data_x_test,data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing Splines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smooting_splines(data_x,data_x_test,data_y):\n",
    "    # Imports #\n",
    "    #---------#\n",
    "    import rpy2.robjects as robjects # Work directly from R (since smoothing splines packages is better)\n",
    "\n",
    "    # Coercion #\n",
    "    #----------#\n",
    "    # Training Data\n",
    "    data_y_vec = np.array(data_y)\n",
    "    data_x_vec = np.array(data_x).reshape(-1,)\n",
    "    # Testing Data\n",
    "    data_x_test_vec = np.array(data_x_test).reshape(-1,)\n",
    "    r_y = robjects.FloatVector(data_y_vec)\n",
    "    r_x = robjects.FloatVector(data_x_vec)\n",
    "\n",
    "    # Training #\n",
    "    #----------#\n",
    "    r_smooth_spline = robjects.r['smooth.spline'] #extract R function# run smoothing function\n",
    "    spline1 = r_smooth_spline(x=r_x, y=r_y, spar=0.7)\n",
    "    f_hat_smoothing_splines=np.array(robjects.r['predict'](spline1,robjects.FloatVector(data_x_vec)).rx2('y'))\n",
    "\n",
    "    # Prediction #\n",
    "    #------------#\n",
    "    # Train\n",
    "    f_hat_smoothing_splines_train=np.array(robjects.r['predict'](spline1,robjects.FloatVector(data_x_vec)).rx2('y'))\n",
    "    # Test\n",
    "    f_hat_smoothing_splines_test=np.array(robjects.r['predict'](spline1,robjects.FloatVector(data_x_test_vec)).rx2('y'))\n",
    "\n",
    "    # Return Outputs\n",
    "    return f_hat_smoothing_splines_train, f_hat_smoothing_splines_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Get Predictions from training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_hat_smoothing_splines_train, f_hat_smoothing_splines_test = get_smooting_splines(data_x,data_x_test,data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Boosted Regression Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GBRF(X_train,X_test,y_train):\n",
    "\n",
    "    # Run Random Forest Util\n",
    "    rand_forest_model_grad_boosted = GradientBoostingRegressor()\n",
    "\n",
    "    # Grid-Search CV\n",
    "    Random_Forest_GridSearch = RandomizedSearchCV(estimator = rand_forest_model_grad_boosted,\n",
    "                                                  n_iter=n_iter_trees,\n",
    "                                                  cv=KFold(CV_folds, random_state=2020, shuffle=True),\n",
    "                                                  param_distributions=Rand_Forest_Grid,\n",
    "                                                  return_train_score=True,\n",
    "                                                  random_state=2020,\n",
    "                                                  verbose=10,\n",
    "                                                  n_jobs=n_jobs)\n",
    "\n",
    "    random_forest_trained = Random_Forest_GridSearch.fit(X_train,y_train)\n",
    "    random_forest_trained = random_forest_trained.best_estimator_\n",
    "\n",
    "    #--------------------------------------------------#\n",
    "    # Write: Model, Results, and Best Hyper-Parameters #\n",
    "    #--------------------------------------------------#\n",
    "\n",
    "    # Save Model\n",
    "    # pickle.dump(random_forest_trained, open('./outputs/models/Gradient_Boosted_Tree/Gradient_Boosted_Tree_Best.pkl','wb'))\n",
    "\n",
    "    # Save Readings\n",
    "    cur_path = os.path.expanduser('./outputs/tables/best_params_Gradient_Boosted_Tree.txt')\n",
    "    with open(cur_path, \"w\") as f:\n",
    "        f.write(str(Random_Forest_GridSearch.best_params_))\n",
    "\n",
    "    best_params_table_tree = pd.DataFrame({'N Estimators': [Random_Forest_GridSearch.best_params_['n_estimators']],\n",
    "                                        'Min Samples Leaf': [Random_Forest_GridSearch.best_params_['min_samples_leaf']],\n",
    "                                        'Learning Rate': [Random_Forest_GridSearch.best_params_['learning_rate']],\n",
    "                                        'Max Depth': [Random_Forest_GridSearch.best_params_['max_depth']],\n",
    "                                        })\n",
    "    \n",
    "    # Count Number of Parameters in Random Forest Regressor\n",
    "    N_tot_params_per_tree = [ (x[0].tree_.node_count)*random_forest_trained.n_features_ for x in random_forest_trained.estimators_]\n",
    "    N_tot_params_in_forest = sum(N_tot_params_per_tree)\n",
    "    best_params_table_tree['N_parameters'] = [N_tot_params_in_forest]\n",
    "    # Write Best Parameter(s)\n",
    "    best_params_table_tree.to_latex('./outputs/tables/Best_params_table_Gradient_Boosted_Tree.txt')\n",
    "    #---------------------------------------------#\n",
    "    \n",
    "    # Generate Prediction(s) #\n",
    "    #------------------------#\n",
    "    y_train_hat_random_forest_Gradient_boosting = random_forest_trained.predict(X_train)\n",
    "    y_test_hat_random_forest_Gradient_boosting = random_forest_trained.predict(X_test)\n",
    "    \n",
    "    # Return Predictions #\n",
    "    #--------------------#\n",
    "    return y_train_hat_random_forest_Gradient_boosting, y_test_hat_random_forest_Gradient_boosting, random_forest_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBRF_y_hat_train, GBRF_y_hat_test, GBRF_model = get_GBRF(data_x,data_x_test,data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffNN_y_hat_train,ffNN_y_hat_test = build_ffNN(n_folds = CV_folds, \n",
    "                                             n_jobs = n_jobs, \n",
    "                                             n_iter = n_iter, \n",
    "                                             param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                             X_train = data_x, \n",
    "                                             y_train = data_y,\n",
    "                                             X_test = data_x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
