{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEU PCA\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_Rank = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEW IMPORTS - TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Grids Build and Loaded!\n",
      "Complete NEU-Structure Building Procedure!!!\n",
      "Complete NEU-Structure Building Procedure!!!\n",
      "Complete NEU-ffNN Training Procedure!!!\n",
      "Deep Feature Builder - Ready\n",
      "Complete NEU-ffNN Training Procedure!!!\n",
      "Complete NEU-ffNN Training Procedure!!!\n",
      "Complete NEU-ffNN (Fully Coupled) Training Procedure!!!\n",
      "Complete NEU-ffNN Training Procedure!!!\n",
      "Complete NEU-ffNN Training Procedure!!!\n",
      "Complete NEU-PCA Training Procedure!!!\n"
     ]
    }
   ],
   "source": [
    "# First Round Initializations (Global Level) #\n",
    "#============================================#\n",
    "# Load Dependances and makes path(s)\n",
    "exec(open('Initializations_Dump.py').read())\n",
    "# Load Hyper( and meta) parameter(s)\n",
    "exec(open('HyperParameter_Grid.py').read())\n",
    "# %run Helper_Functions.ipynb\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Load Models\n",
    "# %run Architecture_Builder.ipynb\n",
    "exec(open('Architecture_Builder.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "yield_data = pd.read_excel('inputs/data/ust_daily.ods', engine='odf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_data['date'] = yield_data['date'].apply(lambda x: x.strftime('%m/%d/%Y'))\n",
    "dates_index = yield_data['date']\n",
    "yield_data.set_index('date', drop=True, inplace=True)\n",
    "yield_data.index.names = [None]\n",
    "Yield_data = yield_data#.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-set Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#================================================#\n",
      " Training Datasize: 5126 and test datasize: 1708.  \n",
      "#================================================#\n"
     ]
    }
   ],
   "source": [
    "# Get indices\n",
    "N_train_step = int(round(yield_data.shape[0]*Train_step_proportion,0))\n",
    "N_test_set = int(yield_data.shape[0] - round(yield_data.shape[0]*Train_step_proportion,0))\n",
    "# Get Datasets\n",
    "X_train = yield_data[:N_train_step]\n",
    "X_test = yield_data[-N_test_set:]\n",
    "# Update User\n",
    "print('#================================================#')\n",
    "print(' Training Datasize: '+str(X_train.shape[0])+' and test datasize: ' + str(X_test.shape[0]) + '.  ')\n",
    "print('#================================================#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Preview:\n",
      "            BC_1MONTH  BC_3MONTH  BC_6MONTH  BC_1YEAR  BC_2YEAR  BC_3YEAR  \\\n",
      "06/08/1990       0.00       7.96       8.03      8.07      8.33      8.38   \n",
      "06/07/1990       0.00       7.96       8.01      8.07      8.34      8.38   \n",
      "06/11/1990       0.00       7.99       8.07      8.09      8.36      8.41   \n",
      "06/13/1990       0.00       7.93       7.99      8.02      8.27      8.32   \n",
      "06/12/1990       0.00       7.99       8.05      8.09      8.36      8.42   \n",
      "...               ...        ...        ...       ...       ...       ...   \n",
      "09/10/2010       0.10       0.14       0.19      0.27      0.58      0.88   \n",
      "09/09/2010       0.10       0.14       0.19      0.26      0.57      0.87   \n",
      "09/28/2010       0.08       0.16       0.20      0.26      0.37      0.64   \n",
      "09/27/2010       0.08       0.16       0.19      0.26      0.44      0.66   \n",
      "09/29/2010       0.12       0.16       0.20      0.27      0.44      0.67   \n",
      "\n",
      "            BC_5YEAR  BC_7YEAR  BC_10YEAR  BC_20YEAR  BC_30YEAR  \\\n",
      "06/08/1990      8.42      8.51       8.46       0.00       8.44   \n",
      "06/07/1990      8.41      8.49       8.46       0.00       8.43   \n",
      "06/11/1990      8.43      8.52       8.48       0.00       8.45   \n",
      "06/13/1990      8.35      8.44       8.40       0.00       8.39   \n",
      "06/12/1990      8.44      8.52       8.48       0.00       8.45   \n",
      "...              ...       ...        ...        ...        ...   \n",
      "09/10/2010      1.59      2.24       2.81       3.58       3.88   \n",
      "09/09/2010      1.57      2.20       2.77       3.54       3.84   \n",
      "09/28/2010      1.25      1.85       2.48       3.35       3.66   \n",
      "09/27/2010      1.31      1.92       2.54       3.40       3.70   \n",
      "09/29/2010      1.28      1.91       2.52       3.38       3.69   \n",
      "\n",
      "            BC_30YEARDISPLAY  \n",
      "06/08/1990               0.0  \n",
      "06/07/1990               0.0  \n",
      "06/11/1990               0.0  \n",
      "06/13/1990               0.0  \n",
      "06/12/1990               0.0  \n",
      "...                      ...  \n",
      "09/10/2010               0.0  \n",
      "09/09/2010               0.0  \n",
      "09/28/2010               0.0  \n",
      "09/27/2010               0.0  \n",
      "09/29/2010               0.0  \n",
      "\n",
      "[5126 rows x 12 columns]\n",
      "Testing Dataset Preview:\n",
      "            BC_1MONTH  BC_3MONTH  BC_6MONTH  BC_1YEAR  BC_2YEAR  BC_3YEAR  \\\n",
      "10/01/2010       0.15       0.16       0.19      0.26      0.42      0.63   \n",
      "09/30/2010       0.14       0.16       0.19      0.27      0.42      0.64   \n",
      "09/21/2010       0.12       0.17       0.20      0.26      0.43      0.68   \n",
      "09/20/2010       0.12       0.17       0.20      0.26      0.47      0.73   \n",
      "09/22/2010       0.12       0.16       0.19      0.25      0.44      0.68   \n",
      "...               ...        ...        ...       ...       ...       ...   \n",
      "04/18/2017       0.76       0.82       0.94      1.02      1.18      1.35   \n",
      "04/19/2017       0.75       0.81       0.94      1.02      1.19      1.38   \n",
      "04/14/2017       0.00       0.00       0.00      0.00      0.00      0.00   \n",
      "04/20/2017       0.73       0.79       0.93      1.01      1.21      1.41   \n",
      "04/21/2017       0.72       0.79       0.92      0.99      1.20      1.40   \n",
      "\n",
      "            BC_5YEAR  BC_7YEAR  BC_10YEAR  BC_20YEAR  BC_30YEAR  \\\n",
      "10/01/2010      1.26      1.90       2.54       3.40       3.71   \n",
      "09/30/2010      1.27      1.91       2.53       3.38       3.69   \n",
      "09/21/2010      1.34      1.99       2.61       3.49       3.79   \n",
      "09/20/2010      1.43      2.10       2.72       3.57       3.87   \n",
      "09/22/2010      1.33      1.96       2.56       3.43       3.74   \n",
      "...              ...       ...        ...        ...        ...   \n",
      "04/18/2017      1.71      1.98       2.18       2.56       2.84   \n",
      "04/19/2017      1.74      2.02       2.21       2.59       2.87   \n",
      "04/14/2017      0.00      0.00       0.00       0.00       0.00   \n",
      "04/20/2017      1.78      2.06       2.24       2.61       2.89   \n",
      "04/21/2017      1.77      2.05       2.24       2.61       2.89   \n",
      "\n",
      "            BC_30YEARDISPLAY  \n",
      "10/01/2010              0.00  \n",
      "09/30/2010              0.00  \n",
      "09/21/2010              0.00  \n",
      "09/20/2010              0.00  \n",
      "09/22/2010              0.00  \n",
      "...                      ...  \n",
      "04/18/2017              2.84  \n",
      "04/19/2017              2.87  \n",
      "04/14/2017              0.00  \n",
      "04/20/2017              2.89  \n",
      "04/21/2017              2.89  \n",
      "\n",
      "[1708 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print('Training Dataset Preview:')\n",
    "print(X_train)\n",
    "print('Testing Dataset Preview:')\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Seeds for Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy\n",
    "np.random.seed(2020)\n",
    "# Tensorflow\n",
    "tf.random.set_seed(2020)\n",
    "# Python's Seed\n",
    "random.seed(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data-Driven Robustness Hyper-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Driven Robustness Rule:\n",
    "Using [this article](https://www.sciencedirect.com/science/article/pii/S0378375815000403) for the variance estimate.  \n",
    "$$\n",
    "\\hat{\\sigma}^2 \\triangleq\n",
    "\\frac1{(n-1)}\\sum_{1<n\\leq N} (y_n - y_{n-1})^2\n",
    ".\n",
    "$$\n",
    "\n",
    "We couple it to the problem via the following\n",
    "$$\n",
    "\\underset{\\underset{0\\leq w_n\\leq 1}{\\sum_{n\\leq N} w_n=1}}{\\operatorname{argmax}} \\sum_{n\\leq N} w_n L(f(x_n),\\hat{f}(x_n),x_n) - \\sigma^2 \\sum_{n\\leq N} w_n \\ln\\left(\\frac{w_n}{N}\\right)\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "# GET STATISTICAL VARIANCE ESTIMATE\n",
    "var_estimate = np.sum(np.diff(X_train)**2)/(((X_train.shape[0])-1))\n",
    "var_estimate = np.float(round(var_estimate,3))\n",
    "\n",
    "\n",
    "robustness_dictionary = {'robustness_parameter': [var_estimate*factor,var_estimate*2*factor,var_estimate*3*factor]}\n",
    "#==================================================================================#        \n",
    "### Create NEU parameter disctionary by parameters joining model it is upgrading ###\n",
    "#==================================================================================#\n",
    "param_grid_NEU_Nets = {**param_grid_NEU_Nets,\n",
    "                       **robustness_dictionary}\n",
    "\n",
    "param_grid_NEU_Feature_Only_Nets = {**param_grid_NEU_Feature_Only_Nets,\n",
    "                                    **robustness_dictionary}\n",
    "\n",
    "NEU_Structure_Dictionary = {**NEU_Structure_Dictionary,\n",
    "                            **robustness_dictionary}\n",
    "\n",
    "# NEU OLS Keys\n",
    "param_grid_NEU_Reg_Nets = {**param_grid_NEU_Nets,\n",
    "                           **robustness_dictionary}\n",
    "\n",
    "param_grid_NEU_Reg_Nets.pop('height', None)\n",
    "param_grid_NEU_Reg_Nets.pop('depth', None)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchark(s)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute/Initialize PCA\n",
    "pca = PCA(n_components=PCA_Rank)\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Define PCA Rreconstructor\n",
    "def PCA_reconstructor(x_in):\n",
    "    affine_parameterizer = np.matmul(pca.components_,(x_in-pca.mean_))\n",
    "    low_dimensional_reconstructed = np.matmul(np.transpose(pca.components_), affine_parameterizer) + pca.mean_\n",
    "    return low_dimensional_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0,)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-28ec7b60336d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreconstructed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreconstructed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPCA_reconstructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# reconstruction_Errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0,)"
     ]
    }
   ],
   "source": [
    "reconstructed_data = np.zeros(X_train.shape)\n",
    "for i in range(X_train.shape[0]):\n",
    "    reconstructed_data[i:]=PCA_reconstructor(X_train[i,])\n",
    "\n",
    "# reconstruction_Errors\n",
    "reconstruction_errors = np.mean(np.abs(reconstructed_data-X_train),axis=-1)\n",
    "print(np.mean(reconstruction_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
