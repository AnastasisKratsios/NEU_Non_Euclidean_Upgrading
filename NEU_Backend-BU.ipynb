{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP - Tesing DUMP\n",
    "x = np.array([1,-2,.3,-.1])\n",
    "x = tf.keras.backend.constant(x)\n",
    "A = tf.constant(tf.ones(np.array([4,4])))\n",
    "b = tf.constant(tf.ones(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEU Unit (Reconfiguration Map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning & ML\n",
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Layer\n",
    "from keras import utils as np_utils\n",
    "\n",
    "# General\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Message Boxes\n",
    "import tkinter\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Custom Layers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will be combined to form the NEU unit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift Layer: x -> x+c ; c in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(BiasLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bias = self.add_weight('bias',\n",
    "                                    shape=input_shape[1:],\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "    def call(self, x):\n",
    "        return x + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagonal/Scaling Layer: x -> Diag(k_1,...,k_n)* x ; k_i in R\n",
    "\n",
    "Rescaling is a special case of multiplication by a diagonal matrix.  This can be imposed as a weight constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Constraint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-17600966ccd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDiagonalWeight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConstraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"Constrains the weights to be diagonal.\n\u001b[1;32m      3\u001b[0m     \"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Constraint' is not defined"
     ]
    }
   ],
   "source": [
    "class DiagonalWeight(Constraint):\n",
    "    \"\"\"Constrains the weights to be diagonal.\n",
    "    \"\"\"\n",
    "    def __call__(self, w):\n",
    "        N = K.int_shape(w)[-1]\n",
    "        m = K.eye(N)\n",
    "        w *= m\n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function Applying Bump Function Element-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bump_activation(x_in):\n",
    "    x_in_abs = tf.math.abs(x)\n",
    "    x_out = tf.where(tf.math.abs(x) >= 1, 0 , tf.pow(1-x,-1))\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First applies the map $\\psi(x)\\triangleq e^{\\frac1{1-|x|}}I_{\\{|x|<1\\}}$ component-wise.\n",
    "\n",
    "2. Applies the diagonalization map to that output: $ \\left(x_1,\\dots,x_d\\right)\n",
    "                    \\mapsto\n",
    "                \\begin{pmatrix}\n",
    "                x_1 & & 0\\\\\n",
    "                &\\ddots &\\\\\n",
    "                0 & & x_d\\\\\n",
    "                \\end{pmatrix}$\n",
    "3. Adds trainable $d\\times d$ (weight) matrix $A$ and trainable bias (vector) $b \\in \\mathbb{R}^d$ to that output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-afbc186fd5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mbump_function_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCustom_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "class bump_function_layer(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(Custom_layer, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        # add trainable weight\n",
    "        self.weight = self.add_weight(shape=(dim,dim),trainable=True)\n",
    "        # add trainable bias\n",
    "        self.bias = self.add_weight(shape=(dim))\n",
    "\n",
    "    def call(self, input):\n",
    "        # 1) Bump Function\n",
    "        x_in_abs = tf.math.abs(x)\n",
    "        x_thresheld = tf.where(tf.math.abs(x) >= 1, 0 , tf.math.exp(tf.pow(1-x,-1)))\n",
    "        # 2) Map to Diagonal Matrix\n",
    "        x_out = tf.expand_dims(x_thresheld, 1)\n",
    "        # 3) Apply weights and biases\n",
    "        x_out = (x_out * self.weight) + self.bias\n",
    "        # 4) Apply Matrix Exponential\n",
    "        x_out = tf.linalg.expm(x_out)\n",
    "        # Return Output\n",
    "        return x_out\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(bump_function_layer, self).get_config()\n",
    "        config['dim'] = self.dim\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Layer: x -> diag(x) -> Wdiag(x); W trainable affine map from d -> d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code is to hide the main tkinter window\n",
    "root = tkinter.Tk()\n",
    "root.withdraw\n",
    "\n",
    "# Message Box\n",
    "messagebox.showinfo(\"Note\", \"The map x->W(x) need not be invertiable since everything works out after applying exponential map (right now were working in the tangent space of GL_d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Lambda at 0x7f6f59558f50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Lambda(\n",
    "    tf.linalg.diag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-fc08201eb94e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustom_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCustom_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "class Custom_layer(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(Custom_layer, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        # add trainable weight\n",
    "        self.weight = self.add_weight(shape=(dim,dim),trainable=True)\n",
    "        # add trainable bias\n",
    "        self.bias = self.add_weight(shape=(dim))\n",
    "\n",
    "    def call(self, input):\n",
    "        # your function\n",
    "        return (tf.linalg.diag(input)*self.weight) + self.bias\n",
    "    def get_config(self):\n",
    "        config = super(Custom_layer, self).get_config()\n",
    "        config['dim'] = self.dim\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
