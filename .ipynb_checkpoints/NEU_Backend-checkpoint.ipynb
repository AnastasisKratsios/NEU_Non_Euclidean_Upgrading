{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEU Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning & ML\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Layer\n",
    "\n",
    "# General\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Message Boxes\n",
    "import tkinter\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Custom Layers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will be combined to form the NEU unit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shift Layer: x -> x+c ; c in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(BiasLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bias = self.add_weight('bias',\n",
    "                                    shape=input_shape[1:],\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "    def call(self, x):\n",
    "        return x + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagonal/Scaling Layer: x -> Diag(k_1,...,k_n)* x ; k_i in R\n",
    "\n",
    "Rescaling is a special case of multiplication by a diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagonalWeight(Constraint):\n",
    "    \"\"\"Constrains the weights to be diagonal.\n",
    "    \"\"\"\n",
    "    def __call__(self, w):\n",
    "        N = K.int_shape(w)[-1]\n",
    "        m = K.eye(N)\n",
    "        w *= m\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP\n",
    "x = np.array([1,-2,.3,-.1])\n",
    "x = tf.keras.backend.constant(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Applying Bump Function Element-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bump_activation(x_in):\n",
    "    x_in_abs = tf.math.abs(x)\n",
    "    x_out = tf.where(tf.math.abs(x) >= 1, 0 , tf.pow(1-x,-1))\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda Layer Taking Vector and Mapping it (injectively) to a diagonal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 1. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. , -2. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0.3,  0. ],\n",
       "       [ 0. ,  0. ,  0. , -0.1]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.tensor_diag(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Layer: x -> diag(x) -> Wdiag(x); W trainable affine map from d -> d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ok'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code is to hide the main tkinter window\n",
    "root = tkinter.Tk()\n",
    "root.withdraw\n",
    "\n",
    "# Message Box\n",
    "messagebox.showinfo(\"Note\", \"The map x->W(x) need not be invertiable since everything works out after applying exponential map (right now were working in the tangent space of GL_d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Lambda at 0x7f6f59558f50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Lambda(\n",
    "    tf.linalg.diag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
