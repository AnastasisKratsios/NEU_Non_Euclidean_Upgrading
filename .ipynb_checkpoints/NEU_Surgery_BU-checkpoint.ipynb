{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on current version:\n",
    "**To Try**:\n",
    "- Cayley parameterization](https://planetmath.org/cayleysparameterizationoforthogonalmatrices) of $SU_d$ (since this is really all we need)...*will it be more stable than Lie's parameterization?* Note: it is a homeomorphism so this is great for UAP!\n",
    "- SVD approach to pre-trainining \n",
    "  - (here for procrustes problem)[https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem]\n",
    "  - [here for complexity](https://mathoverflow.net/questions/161252/what-is-the-time-complexity-of-truncated-svd)\n",
    "  \n",
    "- Get the base version working:\n",
    "\n",
    "- Add the tall version..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEU (Reconfigurations Map and Related Functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Algorithm (NEU-OLS)\n",
    "\n",
    "1. Perform Basic Algorithm (in this case OLS)\n",
    "2. Map predictions to their graph; ie $x\\mapsto (x,\\hat{f}_{OLS}(x))$ where $\\hat{f}_{OLS}$ is the least-squares regression function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning & ML\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras as K\n",
    "import keras.backend as Kb\n",
    "from keras.layers import *\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import utils as np_utils\n",
    "from scipy import linalg as scila\n",
    "\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.constraints import NonNeg\n",
    "\n",
    "\n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# General\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Alerts\n",
    "import os as beepsnd\n",
    "\n",
    "# Others\n",
    "import math\n",
    "\n",
    "# Visualization\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# General Outputs\n",
    "print('TensorFlow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_Reconfigurations = 1\n",
    "d = 1 # Dimension of X\n",
    "D = 1 # Dimension of Y\n",
    "\n",
    "\n",
    "# Data Meta-Parameters\n",
    "noise_level = 0.1\n",
    "uncertainty_level= 0.5\n",
    "\n",
    "# Training meta-parameters\n",
    "Pre_Epochs = 2\n",
    "Full_Epochs = 5\n",
    "\n",
    "# # Height Per Reconfiguration\n",
    "Height_factor_Per_reconfig = d+D\n",
    "Initial_Depth = 1\n",
    "Initial_Height = 50\n",
    "\n",
    "\n",
    "# Number of Datapoints\n",
    "N_data = 10**3\n",
    "# Unknown Function\n",
    "def unknown_f(x):\n",
    "    return x#np.sin(2*x) #+ (x % 2)\n",
    "\n",
    "# Generate Data\n",
    "%run Data_Generator.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for NEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Data Into Compatible Shape\n",
    "data_x = np.array(data_x).reshape(-1,d)\n",
    "data_y = np.array(data_y)\n",
    "# Perform OLS Regression\n",
    "linear_model = LinearRegression()\n",
    "reg = linear_model.fit(data_x, data_y)\n",
    "model_pred_y = linear_model.predict(data_x)\n",
    "# Map to Graph\n",
    "data_NEU = np.concatenate((data_x,model_pred_y.reshape(-1,D)),1)\n",
    "NEU_targets_full  = np.concatenate((data_x,data_y.reshape(-1,D)),1)\n",
    "NEU_targets  = data_y.reshape(-1,D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def above_percentile(x, p): #assuming the input is flattened: (n,)\n",
    "\n",
    "    samples = Kb.cast(Kb.shape(x)[0], Kb.floatx()) #batch size\n",
    "    p =  (100. - p)/100.  #100% will return 0 elements, 0% will return all elements\n",
    "\n",
    "    #samples to get:\n",
    "        #you can choose tf.math.ceil above, it depends on whether you want to\n",
    "        #include or exclude one element. Suppose you you want 33% top,\n",
    "        #but it's only possible to get exactly 30% or 40% top:\n",
    "        #floor will get 30% top and ceil will get 40% top.\n",
    "        #(exact matches included in both cases)\n",
    "\n",
    "    #selected samples\n",
    "    values, indices = tf.math.top_k(x, samples)\n",
    "\n",
    "    return values\n",
    "\n",
    "# def Robust_MSE(p):\n",
    "#     def loss(y_true, y_predicted):\n",
    "#         ses = Kb.pow(y_true-y_predicted,2)\n",
    "#         above = above_percentile(Kb.flatten(ses), p)\n",
    "#         return Kb.mean(above)\n",
    "#     return loss\n",
    "def Robust_MSE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    y_true.shape = (y_true.shape[0], 1)\n",
    "    y_pred.shape = (y_pred.shape[0], 1)\n",
    "\n",
    "    # Compute Exponential Utility\n",
    "    loss_out = np.abs((y_true - y_pred))\n",
    "    loss_out = np.math.exp(-p*loss_out)\n",
    "    loss_out = np.mean(loss_out)\n",
    "    return loss_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\operatorname{SAff}_{d}(\\mathbb{R}) \\cong \\mathbb{R}^d \\rtimes \\operatorname{SL}_{d}(\\mathbb{R})$  Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: $A \\in \\operatorname{SL}_d(\\mathbb{R})$ if and only if $A=\\frac1{\\sqrt[d]{\\det(\\exp(X))}} \\exp(X)$ for some $d\\times d$ matrix $X$.  \n",
    "\n",
    "*Why?*... We use the fact that $\\det(k A) = k^d \\det(A)$ for any $k \\in \\mathbb{R}$ and any $d\\times d$ matrix A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Special_Affine_Layer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=16, input_dim=32):\n",
    "        super(Special_Affine_Layer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Tangential Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # For Numerical Stability (problems with Tensorflow's Exp rounding)\n",
    "#         self.Id = self.add_weight(name='Identity_Matrix',\n",
    "#                                    shape=(input_shape[-1],input_shape[-1]),\n",
    "#                                    initializer='identity',\n",
    "#                                    trainable=False)\n",
    "#         self.num_stab_param = self.add_weight(name='matrix_exponential_stabilizer',\n",
    "#                                               shape=[1],\n",
    "#                                               initializer=RandomUniform(minval=0.0, maxval=0.01),\n",
    "#                                               trainable=True,\n",
    "#                                               constraint=tf.keras.constraints.NonNeg())\n",
    "        # Element of gld\n",
    "#         self.glw = self.add_weight(name='Tangential_Weights',\n",
    "#                                    shape=(input_shape[-1],input_shape[-1]),\n",
    "#                                    initializer='GlorotUniform',\n",
    "#                                    trainable=True)\n",
    "        \n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Euclidean Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        self.b = self.add_weight(name='location_parameter',\n",
    "                                 shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=False)\n",
    "        # Wrap things up!\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, input):\n",
    "        # Build Tangential Feed-Forward Network (Bonus)\n",
    "        #-----------------------------------------------#\n",
    "#         GLN = tf.linalg.expm(self.glw)\n",
    "#         GLN_det = tf.linalg.det(GLN)\n",
    "#         GLN_det = tf.pow(tf.abs(GLN_det),(1/(d+D)))\n",
    "#         SLN = tf.math.divide(GLN,GLN_det)\n",
    "        \n",
    "        # Exponentiation and Action\n",
    "        #----------------------------#\n",
    "        x_out = input\n",
    "#         x_out = tf.linalg.matvec(SLN,x_out)\n",
    "        x_out = x_out + self.b\n",
    "        \n",
    "        # Return Output\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep GLd Layer:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Deep-GL}_d(x) \\triangleq& f^{Depth}\\circ \\dots f^1(x)\\\\\n",
    "f^i(x)\\triangleq &\\exp(A_2) \\operatorname{Leaky-ReLU}\\left(\n",
    "\\exp(A_1)x + b_1\n",
    "\\right)+ b_2\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $A_i$ are $d\\times d$ matrices and $b_i \\in \\mathbb{R}^d$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_GLd_Layer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=16, input_dim=32):\n",
    "        super(Deep_GLd_Layer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Tangential Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # For Numerical Stability (problems with Tensorflow's Exp rounding)\n",
    "#         self.Id = self.add_weight(name='Identity_Matrix',\n",
    "#                                    shape=(input_shape[-1],input_shape[-1]),\n",
    "#                                    initializer='identity',\n",
    "#                                    trainable=False)\n",
    "#         self.num_stab_param = self.add_weight(name='matrix_exponential_stabilizer',\n",
    "#                                               shape=[1],\n",
    "#                                               initializer=RandomUniform(minval=0.0, maxval=0.01),\n",
    "#                                               trainable=True,\n",
    "#                                               constraint=tf.keras.constraints.NonNeg())\n",
    "#         Element of gl_d\n",
    "        self.glw = self.add_weight(name='Tangential_Weights',\n",
    "                                   shape=(input_shape[-1],input_shape[-1]),\n",
    "                                   initializer='GlorotUniform',\n",
    "                                   trainable=True)\n",
    "        self.glw2 = self.add_weight(name='Tangential_Weights2',\n",
    "                                       shape=(input_shape[-1],input_shape[-1]),\n",
    "                                       initializer='GlorotUniform',\n",
    "                                       trainable=True)\n",
    "        \n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Euclidean Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        self.b = self.add_weight(name='location_parameter',\n",
    "                                 shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=False)\n",
    "        self.b2 = self.add_weight(name='location_parameter2',\n",
    "                                 shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=False)\n",
    "        # Wrap things up!\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, input):\n",
    "        # Build Tangential Feed-Forward Network (Bonus)\n",
    "        #-----------------------------------------------#\n",
    "        GLN = tf.linalg.expm(self.glw)\n",
    "#         GLN_det = tf.linalg.det(GLN)\n",
    "#         GLN_det = tf.pow(tf.abs(GLN_det),(1/(d+D)))\n",
    "#         SLN = tf.math.divide(GLN,GLN_det)\n",
    "        GLN2 = tf.linalg.expm(self.glw2)\n",
    "#         GLN_det2 = tf.linalg.det(GLN2)\n",
    "#         GLN_det2 = tf.pow(tf.abs(GLN_det2),(1/(d+D)))\n",
    "#         SLN2 = tf.math.divide(GLN2,GLN_det2)\n",
    "        \n",
    "        # Exponentiation and Action\n",
    "        #----------------------------#\n",
    "        x_out = input\n",
    "\n",
    "        x_out = tf.linalg.matvec(GLN,x_out)\n",
    "        x_out = x_out + self.b\n",
    "        x_out = tf.nn.leaky_relu(x_out)\n",
    "        x_out = tf.linalg.matvec(GLN2,x_out)\n",
    "        x_out = x_out + self.b2\n",
    "        \n",
    "        # Return Output\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Reconfiguration Unit\n",
    "*Lie Version:* $$\n",
    "x \\mapsto \\exp\\left(\n",
    "%\\psi(a\\|x\\|+b)\n",
    "\\operatorname{Skew}_d\\left(\n",
    "    F(\\|x\\|)\n",
    "\\right)\n",
    "\\right) x.\n",
    "$$\n",
    "\n",
    "*Cayley version:*\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x \\mapsto & \\left[(I_d + A(x))(I- A(x))^{-1}\\right]x\n",
    "\\\\\n",
    "A(x)\\triangleq &%\\psi(a\\|x\\|+b)\n",
    "\\operatorname{Skew}_d\\left(\n",
    "    F(\\|x\\|)\\right).\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_inputs = 1\n",
    "Id = tf.linalg.eye(d+D)\n",
    "Tw1 = tf.ones([20,((d+D)**2)])\n",
    "Tw2 = tf.ones([((d+D)**2),20])\n",
    "# # Build Tangential Feed-Forward Network (Bonus)\n",
    "# #-----------------------------------------------#\n",
    "tangential_ffNN = norm_inputs*Id\n",
    "tangential_ffNN = tf.reshape(tangential_ffNN,[((d+D)**2),1])\n",
    "#         tangential_ffNN = tangential_ffNN + Tb1\n",
    "\n",
    "tangential_ffNN = tf.linalg.matmul(Tw1,tangential_ffNN)         \n",
    "# #         tangential_ffNN = tf.nn.relu(tangential_ffNN)\n",
    "tangential_ffNN = tf.linalg.matmul(Tw2,tangential_ffNN)\n",
    "# # #         tangential_ffNN = tangential_ffNN + self.Tb2\n",
    "# tangential_ffNN = tf.reshape(tangential_ffNN,[(d+D),(d+D)])\n",
    "# tangential_ffNN = tf.reshape(tangential_ffNN,[(d+D),(d+D)])\n",
    "tangential_ffNN.shape\n",
    "# Tw2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reconfiguration_unit(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=16, input_dim=32):\n",
    "        super(Reconfiguration_unit, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Center\n",
    "        #------------------------------------------------------------------------------------#\n",
    "#         self.location = self.add_weight(name='location',\n",
    "#                                     shape=(self.units,),\n",
    "#                                     initializer='random_normal',\n",
    "#                                     trainable=True)\n",
    "        \n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Bump Function\n",
    "        #------------------------------------------------------------------------------------#\n",
    "#         self.sigma = self.add_weight(name='bump_threshfold',\n",
    "#                                         shape=[1],\n",
    "#                                         initializer=RandomUniform(minval=.5, maxval=1),\n",
    "#                                         trainable=True,\n",
    "#                                         constraint=tf.keras.constraints.NonNeg())\n",
    "#         self.a = self.add_weight(name='bump_scale',\n",
    "#                                         shape=[1],\n",
    "#                                         initializer='ones',\n",
    "#                                         trainable=True)\n",
    "#         self.b = self.add_weight(name='bump_location',\n",
    "#                                         shape=[1],\n",
    "#                                         initializer='zeros',\n",
    "#                                         trainable=True)\n",
    "\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Tangential Map\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        self.Id = self.add_weight(name='Identity_Matrix',\n",
    "                                   shape=(input_shape[-1],input_shape[-1]),\n",
    "                                   initializer='identity',\n",
    "                                   trainable=False)\n",
    "        self.Tw1 = self.add_weight(name='Tangential_Weights_1 ',\n",
    "                                   shape=(self.units,((d+D)**2)),\n",
    "                                   initializer='GlorotUniform',\n",
    "                                   trainable=True)        \n",
    "        self.Tw2 = self.add_weight(name='Tangential_Weights_2 ',\n",
    "                                   shape=(((d+D)**2),self.units),\n",
    "                                   initializer='GlorotUniform',\n",
    "                                   trainable=True)\n",
    "        self.Tb1 = self.add_weight(name='Tangential_basies_1',\n",
    "                                   shape=(((input_shape[-1])**2),1),\n",
    "                                   initializer='GlorotUniform',\n",
    "                                   trainable=True)\n",
    "        self.Tb2 = self.add_weight(name='Tangential_basies_1',\n",
    "                                   shape=((d+D),(d+D)),\n",
    "                                   initializer='GlorotUniform',\n",
    "                                   trainable=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.num_stab_param = self.add_weight(name='matrix_exponential_stabilizer',shape=[1],initializer=RandomUniform(minval=0.0, maxval=0.01),trainable=True,constraint=tf.keras.constraints.NonNeg())\n",
    "        \n",
    "        # Wrap things up!\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def bump_function(self, x):\n",
    "        return tf.math.exp(-self.sigma / (self.sigma - x))\n",
    "\n",
    "        \n",
    "    def call(self, input):\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Initializations\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        norm_inputs = tf.norm(input) #WLOG if norm is squared!\n",
    "        \n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Bump Function\n",
    "        #------------------------------------------------------------------------------------#\n",
    "#         bump_input = self.a *norm_inputs + self.b\n",
    "#         greater = tf.math.greater(bump_input, -self.sigma)\n",
    "#         less = tf.math.less(bump_input, self.sigma)\n",
    "#         condition = tf.logical_and(greater, less)\n",
    "\n",
    "#         output_bump = tf.where(\n",
    "#             condition, \n",
    "#             self.bump_function(bump_input),\n",
    "#             0.0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Tangential Map\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Build Radial, Tangent-Space Valued Function, i.e.: C(R^d,so_d) st. f(x)=f(y) if |x|=|y|\n",
    "        \n",
    "        \n",
    "        # Build Tangential Feed-Forward Network (Bonus)\n",
    "        #-----------------------------------------------#\n",
    "        tangential_ffNN = norm_inputs*self.Id\n",
    "        tangential_ffNN = tf.reshape(tangential_ffNN,[((d+D)**2),1])\n",
    "        tangential_ffNN = tangential_ffNN + self.Tb1\n",
    "        \n",
    "        tangential_ffNN = tf.linalg.matmul(self.Tw1,tangential_ffNN)         \n",
    "        tangential_ffNN = tf.nn.relu(tangential_ffNN)\n",
    "        tangential_ffNN = tf.linalg.matmul(self.Tw2,tangential_ffNN)\n",
    "        tangential_ffNN = tf.reshape(tangential_ffNN,[(d+D),(d+D)])\n",
    "        tangential_ffNN = tangential_ffNN + self.Tb2\n",
    "    \n",
    "        # Map to Rotation-Matrix-Valued Function #\n",
    "        #----------------------------------------#\n",
    "        tangential_ffNN = (tf.transpose(tangential_ffNN) - tangential_ffNN) \n",
    "#         tangential_ffNN = output_bump*tangential_ffNN\n",
    "        tangential_ffNN = tangential_ffNN + self.num_stab_param*tf.linalg.diag(tf.ones(d+D))\n",
    "            \n",
    "        # Cayley Transformation (Stable):\n",
    "        tangential_ffNN = tf.linalg.matmul((self.Id + tangential_ffNN),tf.linalg.inv(self.Id - tangential_ffNN)) # Lie Parameterization (Numerically Unstable):  #tangential_ffNN = tf.linalg.expm(tangential_ffNN)\n",
    "        \n",
    "        # Exponentiation and Action\n",
    "        #----------------------------#\n",
    "#         x_out = tf.linalg.matvec(tangential_ffNN,(input-self.location)) + self.location\n",
    "        x_out = tf.linalg.matvec(tangential_ffNN,input)\n",
    "        \n",
    "        # Return Output\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit the base model\n",
    "def get_base_model(trainx, trainy, Pre_Epochs_in, depth, height):\n",
    "    # Define Model\n",
    "    #----------------#\n",
    "    # Initialize\n",
    "    input_layer = tf.keras.Input(shape=[d+D])\n",
    "    \n",
    "    # Apply Reconfiguration Unit\n",
    "    output_layer  = Reconfiguration_unit(height)(input_layer)\n",
    "    \n",
    "    if depth > 0:\n",
    "        output_layer = Special_Affine_Layer(d+D)(output_layer)\n",
    "        output_layer  = Reconfiguration_unit(height)(output_layer)\n",
    "    \n",
    "    # Output\n",
    "#     output_layer = projection_layer(output_layer)\n",
    "    reconfiguration_basic = tf.keras.Model(inputs=[input_layer], outputs=[output_layer])\n",
    "    \n",
    "    # Compile Model\n",
    "    #----------------#\n",
    "    # Define Optimizer\n",
    "    optimizer_on = tf.keras.optimizers.SGD(learning_rate=10**(-2), momentum=0.01, nesterov=True)\n",
    "    # Compile\n",
    "    reconfiguration_basic.compile(loss = 'mae',\n",
    "                    optimizer = optimizer_on,\n",
    "                    metrics = ['mse'])\n",
    "    \n",
    "    # Fit Model\n",
    "    #----------------#\n",
    "    reconfiguration_basic.fit(trainx, trainy, epochs=Pre_Epochs_in, verbose=0)\n",
    "        \n",
    "    # Return Output\n",
    "    return reconfiguration_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit the base model\n",
    "def get_base_model_deep_GLd(trainx, trainy, Full_Epochs_in, depth):\n",
    "    # Define Model\n",
    "    #----------------#\n",
    "    # Initialize\n",
    "    input_layer = tf.keras.Input(shape=[d+D])\n",
    "    \n",
    "    # Apply Reconfiguration Unit\n",
    "    output_layer = Deep_GLd_Layer(d+D)(input_layer)\n",
    "    \n",
    "    if depth > 0:\n",
    "        output_layer = Deep_GLd_Layer(d+D)(output_layer)\n",
    "    \n",
    "    # Output\n",
    "#     output_layer = projection_layer(output_layer)\n",
    "    reconfiguration_basic = tf.keras.Model(inputs=[input_layer], outputs=[output_layer])\n",
    "    \n",
    "    # Compile Model\n",
    "    #----------------#\n",
    "    # Define Optimizer\n",
    "    optimizer_on = tf.keras.optimizers.SGD(learning_rate=10**(-2), momentum=0.01, nesterov=True)\n",
    "    # Compile\n",
    "    reconfiguration_basic.compile(loss = 'mae',\n",
    "                    optimizer = optimizer_on,\n",
    "                    metrics = ['mse'])\n",
    "    \n",
    "    # Fit Model\n",
    "    #----------------#\n",
    "    reconfiguration_basic.fit(trainx, trainy, epochs=Full_Epochs_in, verbose=10)\n",
    "        \n",
    "    # Return Output\n",
    "    return reconfiguration_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy Initialization of Subsequent Units\n",
    "Build reconfiguration and pre-train using greedy approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reconfiguration_unit_greedily(model, trainx, trainy, Pre_Epochs_in, depth):\n",
    "\n",
    "    # Dissasemble Network\n",
    "    layers = [l for l in model.layers]\n",
    "\n",
    "    # Define new reconfiguration unit to be added\n",
    "    output_layer_new  = Reconfiguration_unit(d+D)(layers[len(layers)-2].output)\n",
    "\n",
    "    if depth > 0:\n",
    "        output_layer_new = Special_Affine_Layer(d+D)(output_layer_new)\n",
    "        output_layer_new  = Reconfiguration_unit(d+D)(output_layer_new)\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        layers[i].trainable = False\n",
    "\n",
    "\n",
    "    # build model\n",
    "    new_model = tf.keras.Model(inputs=[layers[0].input], outputs=output_layer_new)\n",
    "    #new_model.summary()\n",
    "\n",
    "\n",
    "    # Compile new Model\n",
    "    #-------------------#\n",
    "    # Define Optimizer\n",
    "    optimizer_on = tf.keras.optimizers.SGD(learning_rate=10**(-2), momentum=0.01, nesterov=True)\n",
    "    # Compile Model\n",
    "    new_model.compile(loss = 'mae',\n",
    "                    optimizer = optimizer_on,\n",
    "                    metrics = ['mse'])\n",
    "\n",
    "    # Fit Model\n",
    "    #----------------#\n",
    "    new_model.fit(trainx, trainy, epochs=Pre_Epochs_in, verbose=0)\n",
    "\n",
    "    # Return Output\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Compile (entire) reconfiguration using greedy-initializations past from previous helper functions.\n",
    "Train reconfiguration together (initialized by greedy) layer-wise initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reconfiguration(model_greedy_initialized, trainx, trainy, Full_Epochs_in):\n",
    "\n",
    "    # Dissasemble Network\n",
    "    layers = [l for l in model_greedy_initialized.layers]\n",
    "\n",
    "    # Define new reconfiguration unit to be added\n",
    "    output_layer_new  = Special_Affine_Layer(d+D)(layers[len(layers)-2].output)\n",
    "    output_layer_new  = Reconfiguration_unit(d+D)(output_layer_new)\n",
    "    output_layer_new  = Special_Affine_Layer(d+D)(output_layer_new)\n",
    "\n",
    "    # Output Layer\n",
    "#     output_layer_new = projection_layer(output_layer_new)\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        layers[i].trainable = True\n",
    "\n",
    "\n",
    "    # build model\n",
    "    reconfiguration = tf.keras.Model(inputs=[layers[0].input], outputs=output_layer_new)\n",
    "    #new_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "    # Compile new Model\n",
    "    #-------------------#\n",
    "    # Define Optimizer\n",
    "    optimizer_on = tf.keras.optimizers.SGD(learning_rate=10**(-5), momentum=0.01, nesterov=True)\n",
    "\n",
    "    # Compile Model\n",
    "    reconfiguration.compile(loss = 'mae',\n",
    "                    optimizer = optimizer_on,\n",
    "                    metrics = ['mse'])\n",
    "\n",
    "    # Fit Model\n",
    "    #----------------#\n",
    "    reconfiguration.fit(trainx, trainy, epochs=Full_Epochs_in, verbose=1)\n",
    "\n",
    "    # Return Output\n",
    "    return reconfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0307735999084884\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Base Model\n",
    "model = get_base_model(data_NEU,NEU_targets,10,Initial_Depth,Initial_Height)\n",
    "\n",
    "# Greedy Initialization\n",
    "NEU_OLS_Greedy_init = model\n",
    "for i in range(N_Reconfigurations):\n",
    "    # Update Model\n",
    "    NEU_OLS_Greedy_init_temp = add_reconfiguration_unit_greedily(NEU_OLS_Greedy_init,\n",
    "                                                                 data_NEU,\n",
    "                                                                 NEU_targets_full,\n",
    "                                                                 Pre_Epochs,\n",
    "                                                                 Initial_Depth)\n",
    "    \n",
    "    # Check for Blowup\n",
    "    if math.isnan(np.mean(NEU_OLS_Greedy_init.predict(data_NEU))):\n",
    "        NEU_OLS_Greedy_init = NEU_OLS_Greedy_init\n",
    "        break\n",
    "    else: #Update Model if not explosion\n",
    "        NEU_OLS_Greedy_init = NEU_OLS_Greedy_init_temp\n",
    "    \n",
    "    print(np.mean(np.abs((NEU_OLS_Greedy_init.predict(data_NEU) - NEU_targets_full)**2)))\n",
    "    \n",
    "    # Update User on Status of Initialization\n",
    "    print(((i+1)/N_Reconfigurations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NEU-OLS\n",
    "\n",
    "Next we train NEU-OLS, by unfreezing the greedily initialized layers and using SGD on the whole structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3334 samples\n",
      "Epoch 1/5\n",
      "3334/3334 [==============================] - 1s 336us/sample - loss: 8.0380 - mse: 91.0029\n",
      "Epoch 2/5\n",
      "3334/3334 [==============================] - 0s 98us/sample - loss: 8.0376 - mse: 90.9979\n",
      "Epoch 3/5\n",
      "3334/3334 [==============================] - 0s 89us/sample - loss: 8.0373 - mse: 90.9919\n",
      "Epoch 4/5\n",
      "2240/3334 [===================>..........] - ETA: 0s - loss: 8.0298 - mse: 90.6546"
     ]
    }
   ],
   "source": [
    "NEU_OLS = build_reconfiguration(NEU_OLS_Greedy_init,data_NEU,NEU_targets,Full_Epochs_in = Full_Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deep_GLd = get_base_model_deep_GLd(data_NEU,\n",
    "                                   NEU_targets,\n",
    "                                   Full_Epochs_in = Full_Epochs, \n",
    "                                   depth = (N_Reconfigurations*Initial_Depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predictions (for comparison: TEMP)\n",
    "NEU_OLS_single_unit_prediction = model.predict(data_NEU)\n",
    "NEU_OLS_greedy_initializations = NEU_OLS_Greedy_init.predict(data_NEU)\n",
    "NEU_OLS_prediction = NEU_OLS.predict(data_NEU)\n",
    "Deep_GLd_prediction = Deep_GLd.predict(data_NEU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "visualization_grid = np.random.uniform(-10,10,[1000,2])\n",
    "figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Plot Data\n",
    "plt.scatter(visualization_grid[:,0],visualization_grid[:,1],color='red',marker = '.')\n",
    "# Transform Data\n",
    "NEU_OLS_prediction_visualization_init = model.predict(visualization_grid)\n",
    "NEU_OLS_prediction_visualization_Greedy = NEU_OLS_Greedy_init.predict(visualization_grid)\n",
    "NEU_OLS_prediction_visualization = NEU_OLS.predict(visualization_grid)\n",
    "Deep_GLd_prediction_visualization = Deep_GLd.predict(visualization_grid)\n",
    "\n",
    "# Plot Transformed Data\n",
    "plt.scatter(NEU_OLS_prediction_visualization_init[:,0],NEU_OLS_prediction_visualization_init[:,1],color='b',label='Init',marker = '.')\n",
    "plt.scatter(NEU_OLS_prediction_visualization_Greedy[:,0],NEU_OLS_prediction_visualization_Greedy[:,1],color='g',label='NEU_Greedy',marker = '.')\n",
    "plt.scatter(NEU_OLS_prediction_visualization[:,0],NEU_OLS_prediction_visualization[:,1],color='purple',label='NEU',marker = '.')\n",
    "plt.scatter(Deep_GLd_prediction_visualization[:,0],Deep_GLd_prediction_visualization[:,1],color='black',label='NEU',marker = '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed Visualization... evolution of NEU through training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust Figure Details\n",
    "plt.figure(num=None, figsize=(12, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Data Plot\n",
    "plt.plot(data_x,data_y,color='k',label='true',linestyle='--')\n",
    "\n",
    "# Plot Models\n",
    "plt.plot(data_x,model_pred_y,color='r',label='OLS')\n",
    "plt.plot(data_x,NEU_OLS_single_unit_prediction[:,1],color='b',label='NEU_Unit')\n",
    "plt.plot(data_x,NEU_OLS_greedy_initializations[:,1],color='g',label='NEU_Greedy_Init')\n",
    "plt.plot(data_x,NEU_OLS_prediction[:,1],color='purple',label='NEU-OLS')\n",
    "plt.plot(data_x,Deep_GLd_prediction[:,1],color='black',label='Deep_GLd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Succinct graph (results only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust Figure Details\n",
    "plt.figure(num=None, figsize=(12, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Data Plot\n",
    "plt.plot(data_x,true_y,color='k',label='true',linestyle='--')\n",
    "\n",
    "# Plot Models\n",
    "plt.plot(data_x,model_pred_y,color='r',label='OLS')\n",
    "plt.plot(data_x,NEU_OLS_prediction[:,1],color='purple',label='NEU-OLS')\n",
    "plt.plot(data_x,Deep_GLd_prediction[:,1],color='black',label='Deep_GLd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
