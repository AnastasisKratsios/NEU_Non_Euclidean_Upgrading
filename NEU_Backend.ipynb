{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP - Tesing DUMP\n",
    "x = np.array([1,-2,.3,-.1])\n",
    "x = tf.keras.backend.constant(x)\n",
    "A = tf.constant(tf.ones(np.array([4,4])))\n",
    "b = tf.constant(tf.ones(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEU Unit (Reconfiguration Map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning & ML\n",
    "import tensorflow as tf\n",
    "import keras as Kr\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Layer\n",
    "from keras import utils as np_utils\n",
    "\n",
    "# General\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Message Boxes\n",
    "import tkinter\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Custom Layers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will be combined to form the NEU unit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift Layer: x -> x+c ; c in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(BiasLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bias = self.add_weight('bias',\n",
    "                                    shape=input_shape[1:],\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "    def call(self, x):\n",
    "        return x + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconfiguration Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First applies the map $\\psi(x)\\triangleq e^{\\frac1{1-|x|}}I_{\\{|x|<1\\}}$ component-wise.\n",
    "\n",
    "2. Applies the diagonalization map to that output: $ \\left(x_1,\\dots,x_d\\right)\\mapsto\n",
    "                \\begin{pmatrix}\n",
    "                x_1 & & 0\\\\\n",
    "                &\\ddots &\\\\\n",
    "                0 & & x_d\\\\\n",
    "                \\end{pmatrix}$\n",
    "3. Adds trainable $d\\times d$ (weight) matrix $A$ and trainable bias (vector) $b \\in \\mathbb{R}^d$ to that output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bump_function_layer(Kr.layers.Layer):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(Custom_layer, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        # add trainable weight\n",
    "        self.weight = self.add_weight(shape=(dim,dim),trainable=True)\n",
    "        # add trainable bias\n",
    "        self.bias = self.add_weight(shape=(dim))\n",
    "\n",
    "    def call(self, input):\n",
    "        # 1) Bump Function\n",
    "        x_in_abs = tf.math.abs(x)\n",
    "        x_thresheld = tf.where(tf.math.abs(x) >= 1, 0 , tf.math.exp(tf.pow(1-x,-1)))\n",
    "        # 2) Map to Diagonal Matrix\n",
    "        x_out = tf.expand_dims(x_thresheld, 1)\n",
    "        # 3) Apply weights and biases\n",
    "        x_out = (x_out * self.weight) + self.bias\n",
    "        # 4) Apply Matrix Exponential\n",
    "        x_out = tf.linalg.expm(x_out)\n",
    "        # Return Output\n",
    "        return x_out\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(bump_function_layer, self).get_config()\n",
    "        config['dim'] = self.dim\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST MODIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([1, 4])>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_test = tf.constant(np.array([1,2]))\n",
    "b_test = tf.constant(np.array([1,2]))\n",
    "tf.math.multiply(a_test,b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reconfiguration(Kr.layers.Layer):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(Custom_layer, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        # Initialize trainable Linear Endomorphism in Tangent Space\n",
    "        self.weight = self.add_weight(shape=(dim,dim),trainable=True)\n",
    "        # Initialize trainable Affine Shift in Tangent Space\n",
    "        self.bias = self.add_weight(shape=(dim))\n",
    "        # location parameter\n",
    "        self.location = self.add_weight(shape=(dim))\n",
    "        # scaling parameter\n",
    "        self.scale = self.add_weight(shape=(dim))\n",
    "\n",
    "    def call(self, input):\n",
    "        # Shift and scale data\n",
    "        #---------------------#\n",
    "        # Shift \n",
    "        x_shift = input - self.location\n",
    "        # Rescale\n",
    "        x = tf.math.multiply(x_shift,self.scale)\n",
    "        \n",
    "        # Apply bumpy function & tangent space transformation\n",
    "        #----------------------------------------------------#\n",
    "        # 1) Bump Function\n",
    "        x_in_abs = tf.math.abs(x)\n",
    "        x_thresheld = tf.where(tf.math.abs(x) >= 1, 0 , tf.math.exp(tf.pow(1-x,-1)))\n",
    "        # 2) Map to Diagonal Matrix & Apply Bias\n",
    "        x_out = tf.expand_dims((x_thresheld + self.bias), 1) \n",
    "        # 3) Apply weights\n",
    "        x_out = (x_out * self.weight) \n",
    "        # 4) Apply Matrix Exponential\n",
    "        x_out = tf.linalg.expm(x_out)\n",
    "        \n",
    "        # Mulpliply Transformation with shifted data\n",
    "        #--------------------------------------------#\n",
    "        x_out = tf.linalg.matvec(x_out,x_shift)\n",
    "        \n",
    "        # Recenter Data\n",
    "        #---------------#\n",
    "        x_out = x_out + self.location\n",
    "        \n",
    "        # Return Ouput\n",
    "        return x_out\n",
    "        \n",
    "    def reconfiguration(self):\n",
    "        config = super(bump_function_layer, self).get_config()\n",
    "        config['dim'] = self.dim\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
