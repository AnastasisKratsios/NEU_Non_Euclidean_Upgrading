{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Custom Layers\n",
    "- Shift\n",
    "- Special Affine\n",
    "- Euclidean Group-Valued\n",
    "- GLd-Valued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift $\\mathbb{R}^d$  Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cd5266d8e948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mShift_Layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mShift_Layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class Shift_Layers(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=16, input_dim=32):\n",
    "        super(Shift_Layers, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Euclidean Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        self.b = self.add_weight(name='location_parameter',\n",
    "                                 shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=False)\n",
    "        # Wrap things up!\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, input):        \n",
    "        # Exponentiation and Action\n",
    "        #----------------------------#\n",
    "        x_out = input\n",
    "        x_out = x_out + self.b\n",
    "        \n",
    "        # Return Output\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\operatorname{E}_{d}(\\mathbb{R}) \\cong \\mathbb{R}^d \\rtimes \\operatorname{O}_{d}(\\mathbb{R})$  Layers\n",
    "This is the group of all isometries of $\\mathbb{R}^d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Euclidean_Layer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=16, input_dim=32):\n",
    "        super(Euclidean_Layer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Tangential Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # For Numerical Stability (problems with Tensorflow's Exp rounding)\n",
    "        self.Id = self.add_weight(name='Identity_Matrix',\n",
    "                                   shape=(input_shape[-1],input_shape[-1]),\n",
    "                                   initializer='identity',\n",
    "                                   trainable=False)\n",
    "        # Element of gld\n",
    "        self.glw = self.add_weight(name='Tangential_Weights',\n",
    "                                   shape=(input_shape[-1],input_shape[-1]),\n",
    "                                   initializer='GlorotUniform',\n",
    "                                   trainable=True)\n",
    "        \n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Euclidean Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        self.b = self.add_weight(name='location_parameter',\n",
    "                                 shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=False)\n",
    "        # Wrap things up!\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, input):\n",
    "        # Build Tangential Feed-Forward Network (Bonus)\n",
    "        #-----------------------------------------------#\n",
    "        On = tf.linalg.matmul((self.Id + self.glw),tf.linalg.inv(self.Id - self.glw))\n",
    "        \n",
    "        # Exponentiation and Action\n",
    "        #----------------------------#\n",
    "        x_out = input\n",
    "        x_out = tf.linalg.matvec(On,x_out)\n",
    "        x_out = x_out + self.b\n",
    "        \n",
    "        # Return Output\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\operatorname{SAff}_{d}(\\mathbb{R}) \\cong \\mathbb{R}^d \\rtimes \\operatorname{SL}_{d}(\\mathbb{R})$  Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: $A \\in \\operatorname{SL}_d(\\mathbb{R})$ if and only if $A=\\frac1{\\sqrt[d]{\\det(\\exp(X))}} \\exp(X)$ for some $d\\times d$ matrix $X$.  \n",
    "\n",
    "*Why?*... We use the fact that $\\det(k A) = k^d \\det(A)$ for any $k \\in \\mathbb{R}$ and any $d\\times d$ matrix A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-38a319acd40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSpecial_Affine_Layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpecial_Affine_Layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class Special_Affine_Layer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=16, input_dim=32):\n",
    "        super(Special_Affine_Layer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Tangential Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # For Numerical Stability (problems with Tensorflow's Exp rounding)\n",
    "        self.Id = self.add_weight(name='Identity_Matrix',\n",
    "                                   shape=(input_shape[-1],input_shape[-1]),\n",
    "                                   initializer='identity',\n",
    "                                   trainable=False)\n",
    "#         self.num_stab_param = self.add_weight(name='matrix_exponential_stabilizer',\n",
    "#                                               shape=[1],\n",
    "#                                               initializer=RandomUniform(minval=0.0, maxval=0.01),\n",
    "#                                               trainable=True,\n",
    "#                                               constraint=tf.keras.constraints.NonNeg())\n",
    "        # Element of gld\n",
    "        self.glw = self.add_weight(name='Tangential_Weights',\n",
    "                                   shape=(input_shape[-1],input_shape[-1]),\n",
    "                                   initializer='GlorotUniform',\n",
    "                                   trainable=True)\n",
    "        \n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Euclidean Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        self.b = self.add_weight(name='location_parameter',\n",
    "                                 shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=False)\n",
    "        # Wrap things up!\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, input):\n",
    "        # Build Tangential Feed-Forward Network (Bonus)\n",
    "        #-----------------------------------------------#\n",
    "        GLN = tf.linalg.expm(self.glw)\n",
    "        GLN_det = tf.linalg.det(GLN)\n",
    "        GLN_det = tf.pow(tf.abs(GLN_det),(1/(d+D)))\n",
    "        SLN = tf.math.divide(GLN,GLN_det)\n",
    "        \n",
    "        # Exponentiation and Action\n",
    "        #----------------------------#\n",
    "        x_out = input\n",
    "        x_out = tf.linalg.matvec(SLN,x_out)\n",
    "        x_out = x_out + self.b\n",
    "        \n",
    "        # Return Output\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep GLd Layer:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Deep-GL}_d(x) \\triangleq& f^{Depth}\\circ \\dots f^1(x)\\\\\n",
    "f^i(x)\\triangleq &\\exp(A_2) \\operatorname{Leaky-ReLU}\\left(\n",
    "\\exp(A_1)x + b_1\n",
    "\\right)+ b_2\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $A_i$ are $d\\times d$ matrices and $b_i \\in \\mathbb{R}^d$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_GLd_Layer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units=16, input_dim=32):\n",
    "        super(Deep_GLd_Layer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Tangential Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # For Numerical Stability (problems with Tensorflow's Exp rounding)\n",
    "#         self.Id = self.add_weight(name='Identity_Matrix',\n",
    "#                                    shape=(input_shape[-1],input_shape[-1]),\n",
    "#                                    initializer='identity',\n",
    "#                                    trainable=False)\n",
    "#         self.num_stab_param = self.add_weight(name='matrix_exponential_stabilizer',\n",
    "#                                               shape=[1],\n",
    "#                                               initializer=RandomUniform(minval=0.0, maxval=0.01),\n",
    "#                                               trainable=True,\n",
    "#                                               constraint=tf.keras.constraints.NonNeg())\n",
    "#         Element of gl_d\n",
    "        self.glw = self.add_weight(name='Tangential_Weights',\n",
    "                                   shape=(input_shape[-1],input_shape[-1]),\n",
    "                                   initializer='GlorotUniform',\n",
    "                                   trainable=True)\n",
    "        self.glw2 = self.add_weight(name='Tangential_Weights2',\n",
    "                                       shape=(input_shape[-1],input_shape[-1]),\n",
    "                                       initializer='GlorotUniform',\n",
    "                                       trainable=True)\n",
    "        \n",
    "        #------------------------------------------------------------------------------------#\n",
    "        # Euclidean Parameters\n",
    "        #------------------------------------------------------------------------------------#\n",
    "        self.b = self.add_weight(name='location_parameter',\n",
    "                                 shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=False)\n",
    "        self.b2 = self.add_weight(name='location_parameter2',\n",
    "                                 shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=False)\n",
    "        # Wrap things up!\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, input):\n",
    "        # Build Tangential Feed-Forward Network (Bonus)\n",
    "        #-----------------------------------------------#\n",
    "        GLN = tf.linalg.expm(self.glw)\n",
    "        GLN2 = tf.linalg.expm(self.glw2)\n",
    "        \n",
    "        # Exponentiation and Action\n",
    "        #----------------------------#\n",
    "        x_out = input\n",
    "\n",
    "        x_out = tf.linalg.matvec(GLN,x_out)\n",
    "        x_out = x_out + self.b\n",
    "        x_out = tf.nn.leaky_relu(x_out)\n",
    "        x_out = tf.linalg.matvec(GLN2,x_out)\n",
    "        x_out = x_out + self.b2\n",
    "        \n",
    "        # Return Output\n",
    "        return x_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
