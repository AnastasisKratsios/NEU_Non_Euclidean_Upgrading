{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEU-PCA: Financial Data\n",
    "- Designed and Coded by: [Anastasis Kratsios](https://people.math.ethz.ch/~kratsioa/).\n",
    "- Some Elements of the PCA analysis are forked from [this repo](https://github.com/radmerti/MVA2-PCA/blob/master/YieldCurvePCA.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PCA?\n",
    "PCA is a two-part algorithm.  In phase 1, high-dimensional data $\\mathbb{R}^D$ is mapped into a low-dimensional space ($D\\gg d$) via the optimal linear (orthogonal) projection.  In phase 2, the best $d$-dimensional embedding of the features $\\mathbb{R}^d$ into $\\mathbb{R}^D$ is learned and used to reconstruct (as best as is possible) the high-dimensional data from this small set of features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does NEU-PCA function?\n",
    "Since the purpous of the reconfiguration network is to learn (non-linear) topology embeddings of low-dimensional linear space then we can apply NEU to the reconstruction map phase of PCA.  Moreover, we will see that the embedding can be infered from a low-dimensional intermediate space $\\mathbb{R}^N$ with $d\\leq N\\ll D$.  Benefits:\n",
    "- Computationally cheap,\n",
    "- Just as effective as an Autoencoder,\n",
    "- Maintain interpretation of PCA features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension to be Reduced To\n",
    "PCA_Rank = 3\n",
    "## TEMPS!!\n",
    "is_visuallty_verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Initialization Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Round Initializations (Global Level) #\n",
    "#============================================#\n",
    "# Load Dependances and makes path(s)\n",
    "exec(open('Initializations_Dump.py').read())\n",
    "# Load Hyper( and meta) parameter(s)\n",
    "exec(open('HyperParameter_Grid.py').read())\n",
    "# %run Helper_Functions.ipynb\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Load Models\n",
    "# %run Architecture_Builder.ipynb\n",
    "exec(open('Architecture_Builder.py').read())\n",
    "# Initialize \"First Run Mode\"\n",
    "First_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import decomposition\n",
    "import scipy\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Layer, InputSpec\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import regularizers, activations, initializers, constraints, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.constraints import UnitNorm, Constraint\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "# MUSTS\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Seeds for Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy\n",
    "np.random.seed(2020)\n",
    "# Tensorflow\n",
    "tf.random.set_seed(2020)\n",
    "# Python's Seed\n",
    "random.seed(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data-Preparation Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if First_run:\n",
    "    # Load Data\n",
    "    yield_data = pd.read_excel('inputs/data/ust_daily.ods', engine='odf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardcore Maturities Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Maturities = np.array([(1/12),.25,.5,1,2,3,5,7,10,20,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if First_run:\n",
    "    yield_data['date'] = pd.to_datetime(yield_data['date'],infer_datetime_format=True)\n",
    "    yield_data.set_index('date', drop=True, inplace=True)\n",
    "    yield_data.index.names = [None]\n",
    "    # Remove garbage column\n",
    "    yield_data.drop(columns=['BC_30YEARDISPLAY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if First_run:\n",
    "    # # Get indices\n",
    "    N_train_step = int(round(yield_data.shape[0]*Train_step_proportion,0))\n",
    "    N_test_set = int(yield_data.shape[0] - round(yield_data.shape[0]*Train_step_proportion,0))\n",
    "    # # Get Datasets\n",
    "    X_train = yield_data[:N_train_step]\n",
    "    X_test = yield_data[-N_test_set:]\n",
    "    # Transpose\n",
    "    X_train_T = X_train.T\n",
    "    X_test_T = X_test.T\n",
    "    \n",
    "    \n",
    "    # # Update User\n",
    "    print('#================================================#')\n",
    "    print(' Training Datasize: '+str(X_train.shape[0])+' and test datasize: ' + str(X_test.shape[0]) + '.  ')\n",
    "    print('#================================================#')\n",
    "    \n",
    "    # # Set First Run to Off\n",
    "    First_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Train Scaler\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "# Map to Test Set\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_visuallty_verbose:\n",
    "    print('Training Dataset Preview:')\n",
    "    print(X_train.head())\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_visuallty_verbose:\n",
    "    print('Testing Dataset Preview:')\n",
    "    print(X_test.head())\n",
    "    \n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.plot(X_train.index, X_train)\n",
    "plt.xlim(X_train.index.min(), X_train.index.max())\n",
    "plt.ylim(np.min(X_train.min()),np.max(X_train.max()))\n",
    "\n",
    "plt.axhline(y=0,c=\"grey\",linewidth=0.5,zorder=0)\n",
    "for i in range(X_train.index.min().year, X_train.index.max().year+1):\n",
    "    plt.axvline(x=X_train.index[X_train.index.searchsorted(DT.datetime(i,1,1))-1],\n",
    "                c=\"grey\", linewidth=0.5, zorder=0)\n",
    "    \n",
    "plt.legend((np.array(X_train.columns)))\n",
    "\n",
    "# Save \n",
    "plt.savefig('outputs/plotsANDfigures/Data_Visualization_Yield_TimeSeries.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yield Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncols = 6\n",
    "Nrows = 10\n",
    "num_years = X_train.index.max().year-X_train.index.min().year\n",
    "rows = math.ceil(num_years/Ncols)\n",
    "\n",
    "plt.figure(figsize=(24,(24/Ncols)*rows))\n",
    "\n",
    "plt.subplot2grid((rows,Ncols), (0,0), colspan=Ncols, rowspan=Nrows)\n",
    "\n",
    "\n",
    "colnum = 0\n",
    "rownum = 0\n",
    "for year in range(X_train.index.min().year,X_train.index.max().year):\n",
    "    year_start = X_train.index[X_train.index.searchsorted(DT.datetime(year,1,1))]\n",
    "    year_end = X_train.index[X_train.index.searchsorted(DT.datetime(year,12,30))]\n",
    "    \n",
    "    plt.subplot2grid((rows,Ncols), (rownum,colnum), colspan=1, rowspan=1)\n",
    "    plt.title('{0}'.format(year))\n",
    "    plt.xlim(0, len(X_train_T.index)-1)\n",
    "    plt.ylim(np.min(X_train_T.values), np.max(X_train_T.values))\n",
    "    plt.xticks(range(len(X_train_T.index)), X_train_T.index, size='small')\n",
    "    \n",
    "    plt.plot(X_train_T.loc[:,year_start:year_end].values)\n",
    "    \n",
    "    if colnum != Ncols-1:\n",
    "        colnum += 1\n",
    "    else:\n",
    "        colnum = 0\n",
    "        rownum += 1\n",
    "\n",
    "# Save\n",
    "plt.savefig('outputs/plotsANDfigures/Data_Visualization_Annual_Yield_Curves.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Prediction Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark(s)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PCAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct Training Data\n",
    "Zpca,Zpca_test,Rpca,Rpca_test = get_PCAs(X_train_scaled=X_train_scaled.T,\n",
    "                                         X_test_scaled=X_train_scaled.T,\n",
    "                                         PCA_Rank=PCA_Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Reconstruction Result(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Results #\n",
    "#-------------#\n",
    "# Errors (Train): \n",
    "A = pd.DataFrame(Rpca)\n",
    "B = pd.DataFrame(X_train.T)\n",
    "train_results = B.to_numpy()-A.to_numpy()\n",
    "### MSE\n",
    "train_results_MSE = train_results**2\n",
    "train_results_MSE_vect = np.mean(train_results_MSE,axis=1)\n",
    "PCA_Reconstruction_train_results_MSE = np.mean(train_results_MSE_vect)\n",
    "### MAE\n",
    "train_results_MAE = np.abs(train_results)\n",
    "train_results_MAE_vect = np.mean(train_results_MAE,axis=1)\n",
    "PCA_Reconstruction_train_results_MAE = np.mean(train_results_MAE_vect)\n",
    "\n",
    "\n",
    "# Errors (Test): One step ahead prediction errors\n",
    "A = pd.DataFrame(Rpca).iloc[1:]\n",
    "B = pd.DataFrame(X_train.T).iloc[:-1]\n",
    "test_results = B.to_numpy()-A.to_numpy()\n",
    "### MSE\n",
    "test_results_MSE = test_results**2\n",
    "test_results_MSE_vect = np.mean(test_results_MSE,axis=1)\n",
    "PCA_Reconstruction_test_results_MSE = np.mean(test_results_MSE_vect)\n",
    "### MAE\n",
    "test_results_MAE = np.abs(test_results)\n",
    "test_results_MAE_vect = np.mean(test_results_MAE,axis=1)\n",
    "PCA_Reconstruction_test_results_MAE = np.mean(test_results_MAE_vect)\n",
    "\n",
    "\n",
    "# Formatting\n",
    "## Train\n",
    "Performance_Results_train = pd.DataFrame([{'MAE':PCA_Reconstruction_train_results_MAE,\n",
    "                                           'MSE':PCA_Reconstruction_train_results_MSE}],\n",
    "                                        index=['PCA'])\n",
    "## Test\n",
    "Performance_Results_test = pd.DataFrame([{'MAE':PCA_Reconstruction_test_results_MAE,\n",
    "                                          'MSE':PCA_Reconstruction_test_results_MSE}],\n",
    "                                        index=['PCA'])\n",
    "\n",
    "# Save Results #\n",
    "#--------------#\n",
    "Performance_Results_train.to_latex('outputs/tables/Fin_Performance_train.txt')\n",
    "Performance_Results_test.to_latex('outputs/tables/Fin_Performance_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get (ReLU) Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = -1\n",
    "n_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_Reconstructed_train, AE_Reconstructed_test, AE_Factors_train, AE_Factors_test = build_autoencoder(CV_folds,\n",
    "                                                                                    n_jobs,\n",
    "                                                                                    n_iter,\n",
    "                                                                                    X_train_scaled.T,\n",
    "                                                                                    X_train.T,\n",
    "                                                                                    X_train_scaled.T,\n",
    "                                                                                    PCA_Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Reconstruction Result(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Results #\n",
    "#-------------#\n",
    "# Errors (Train): \n",
    "A = pd.DataFrame(AE_Reconstructed_train)\n",
    "B = pd.DataFrame(X_train.T)\n",
    "train_results = B.to_numpy()-A.to_numpy()\n",
    "### MSE\n",
    "train_results_MSE = train_results**2\n",
    "train_results_MSE_vect = np.mean(train_results_MSE,axis=1)\n",
    "AE_Reconstruction_train_results_MSE = np.mean(train_results_MSE_vect)\n",
    "### MAE\n",
    "train_results_MAE = np.abs(train_results)\n",
    "train_results_MAE_vect = np.mean(train_results_MAE,axis=1)\n",
    "AE_Reconstruction_train_results_MAE = np.mean(train_results_MAE_vect)\n",
    "\n",
    "\n",
    "# Errors (Test): One step ahead prediction errors\n",
    "A = pd.DataFrame(AE_Reconstructed_train).iloc[1:]\n",
    "B = pd.DataFrame(X_train.T).iloc[:-1]\n",
    "test_results = B.to_numpy()-A.to_numpy()\n",
    "### MSE\n",
    "test_results_MSE = test_results**2\n",
    "test_results_MSE_vect = np.mean(test_results_MSE,axis=1)\n",
    "AE_Reconstruction_test_results_MSE = np.mean(test_results_MSE_vect)\n",
    "### MAE\n",
    "test_results_MAE = np.abs(test_results)\n",
    "test_results_MAE_vect = np.mean(test_results_MAE,axis=1)\n",
    "AE_Reconstruction_test_results_MAE = np.mean(test_results_MAE_vect)\n",
    "\n",
    "\n",
    "# Formatting\n",
    "## Train\n",
    "AE_Reconstruction_Results_train = pd.DataFrame([{'MAE':PCA_Reconstruction_train_results_MAE,\n",
    "                                                 'MSE':PCA_Reconstruction_train_results_MSE}],index=['AE'])\n",
    "## Test\n",
    "AE_Reconstruction_Results_test = pd.DataFrame([{'MAE':PCA_Reconstruction_train_results_MAE,\n",
    "                                                'MSE':PCA_Reconstruction_train_results_MSE}],index=['AE'])\n",
    "\n",
    "\n",
    "# Update\n",
    "Performance_Results_train = pd.concat([Performance_Results_train,AE_Reconstruction_Results_train],axis=0)\n",
    "Performance_Results_test = pd.concat([Performance_Results_test,AE_Reconstruction_Results_test],axis=0)\n",
    "\n",
    "\n",
    "# Save Results #\n",
    "#--------------#\n",
    "Performance_Results_train.to_latex('outputs/tables/Fin_Performance_train.txt')\n",
    "Performance_Results_test.to_latex('outputs/tables/Fin_Performance_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NEU-PCA: Computing...')\n",
    "NEU_PCA_Reconstruction_train, NEU_PCA_Reconstruction_test, NEU_PCA_Factors_train, NEU_PCA_Factors_test =  build_NEU_PCA(CV_folds, \n",
    "                                                                                                                        n_jobs, \n",
    "                                                                                                                        n_iter, \n",
    "                                                                                                                        param_grid_in, \n",
    "                                                                                                                        X_train_scaled.T,\n",
    "                                                                                                                        X_train.T, \n",
    "                                                                                                                        X_train_scaled.T,\n",
    "                                                                                                                        PCA_Rank)\n",
    "\n",
    "print('NEU-PCA: Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Reconstruction Result(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Results #\n",
    "#-------------#\n",
    "# Errors (Train): \n",
    "A = pd.DataFrame(NEU_PCA_Reconstruction_train)\n",
    "B = pd.DataFrame(X_train.T)\n",
    "train_results = B.to_numpy()-A.to_numpy()\n",
    "### MSE\n",
    "train_results_MSE = train_results**2\n",
    "train_results_MSE_vect = np.mean(train_results_MSE,axis=1)\n",
    "NEU_PCA_Reconstruction_train_results_MSE = np.mean(train_results_MSE_vect)\n",
    "### MAE\n",
    "train_results_MAE = np.abs(train_results)\n",
    "train_results_MAE_vect = np.mean(train_results_MAE,axis=1)\n",
    "NEU_PCA_Reconstruction_train_results_MAE = np.mean(train_results_MAE_vect)\n",
    "\n",
    "\n",
    "# Errors (Test): One step ahead prediction errors\n",
    "A = pd.DataFrame(NEU_PCA_Reconstruction_train).iloc[1:]\n",
    "B = pd.DataFrame(X_train.T).iloc[:-1]\n",
    "test_results = B.to_numpy()-A.to_numpy()\n",
    "### MSE\n",
    "test_results_MSE = test_results**2\n",
    "test_results_MSE_vect = np.mean(test_results_MSE,axis=1)\n",
    "NEU_PCA_Reconstruction_test_results_MSE = np.mean(test_results_MSE_vect)\n",
    "### MAE\n",
    "test_results_MAE = np.abs(test_results)\n",
    "test_results_MAE_vect = np.mean(test_results_MAE,axis=1)\n",
    "NEU_PCA_Reconstruction_test_results_MAE = np.mean(test_results_MAE_vect)\n",
    "\n",
    "\n",
    "# Formatting\n",
    "## Train\n",
    "NEU_Reconstruction_Results_train = pd.DataFrame([{'MAE':NEU_PCA_Reconstruction_train_results_MAE,\n",
    "                                                 'MSE':NEU_PCA_Reconstruction_train_results_MSE}],index=['NEU-PCA'])\n",
    "## Test\n",
    "NEU_Reconstruction_Results_test = pd.DataFrame([{'MAE':NEU_PCA_Reconstruction_test_results_MAE,\n",
    "                                                'MSE':NEU_PCA_Reconstruction_test_results_MSE}],index=['NEU-PCA'])\n",
    "\n",
    "\n",
    "# Update\n",
    "Performance_Results_train = pd.concat([Performance_Results_train,NEU_Reconstruction_Results_train],axis=0)\n",
    "Performance_Results_test = pd.concat([Performance_Results_test,NEU_Reconstruction_Results_test],axis=0)\n",
    "\n",
    "\n",
    "# Save Results #\n",
    "#--------------#\n",
    "Performance_Results_train.to_latex('outputs/tables/Fin_Performance_train.txt')\n",
    "Performance_Results_test.to_latex('outputs/tables/Fin_Performance_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Space(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(AE_Factors_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructed Yield-Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(Performance_Results_test,4))\n",
    "Performance_Results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(Performance_Results_train,4))\n",
    "Performance_Results_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- ---\n",
    "# Fin\n",
    "--- ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
